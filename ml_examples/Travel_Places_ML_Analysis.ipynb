{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad178a96",
   "metadata": {},
   "source": [
    "# Travel Guide Places - Machine Learning Analysis\n",
    "\n",
    "This notebook demonstrates how to use the CSV data exported from your Travel Guide application for machine learning analysis.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure you have downloaded the CSV file from your Travel Guide admin panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f720ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install pandas numpy scikit-learn matplotlib seaborn plotly folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd772b",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "Load the CSV file downloaded from your Travel Guide application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - update the path to your downloaded CSV file\n",
    "df = pd.read_csv('places_ml_ready.csv')  # or 'places.csv'\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(\"Data Info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf06f2",
   "metadata": {},
   "source": [
    "## Data Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Category distribution\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Places by Category')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Region distribution\n",
    "df['region'].value_counts().plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Places by Region')\n",
    "\n",
    "# Visit time distribution\n",
    "df['estimated_time_to_visit'].hist(bins=20, ax=axes[1,0])\n",
    "axes[1,0].set_title('Distribution of Visit Times')\n",
    "axes[1,0].set_xlabel('Hours')\n",
    "\n",
    "# Average visit time by category\n",
    "avg_time = df.groupby('category')['estimated_time_to_visit'].mean().sort_values()\n",
    "avg_time.plot(kind='barh', ax=axes[1,1])\n",
    "axes[1,1].set_title('Average Visit Time by Category')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic visualization (if coordinates are available)\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    valid_coords = df[(df['latitude'] != 0) & (df['longitude'] != 0)]\n",
    "    \n",
    "    if len(valid_coords) > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        scatter = plt.scatter(valid_coords['longitude'], valid_coords['latitude'], \n",
    "                            c=valid_coords['estimated_time_to_visit'], \n",
    "                            cmap='viridis', alpha=0.7, s=100)\n",
    "        plt.colorbar(scatter, label='Visit Time (hours)')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.title('Places by Geographic Location (colored by visit time)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Found {len(valid_coords)} places with valid coordinates\")\n",
    "    else:\n",
    "        print(\"No valid coordinates found in the dataset\")\n",
    "else:\n",
    "    print(\"No coordinate columns found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5aa6e9",
   "metadata": {},
   "source": [
    "## Machine Learning: Predicting Visit Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for ML\n",
    "# Create additional features if not present in ML-ready CSV\n",
    "if 'name_length' not in df.columns:\n",
    "    df['name_length'] = df['name'].str.len()\n",
    "    df['description_length'] = df['description'].str.len()\n",
    "    df['description_word_count'] = df['description'].str.split().str.len()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "if 'category_encoded' not in df.columns:\n",
    "    df['category_encoded'] = le.fit_transform(df['category'].fillna('unknown'))\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = ['name_length', 'description_length', 'description_word_count']\n",
    "\n",
    "# Add encoded features if available\n",
    "if 'category_encoded' in df.columns:\n",
    "    feature_columns.append('category_encoded')\n",
    "if 'region_encoded' in df.columns:\n",
    "    feature_columns.append('region_encoded')\n",
    "if 'popularity_score' in df.columns:\n",
    "    feature_columns.append('popularity_score')\n",
    "\n",
    "# Add coordinates if available and valid\n",
    "if 'latitude' in df.columns and df['latitude'].sum() != 0:\n",
    "    feature_columns.extend(['latitude', 'longitude'])\n",
    "\n",
    "print(\"Features selected for ML model:\", feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95203f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X = df[feature_columns].fillna(0)\n",
    "y = df['estimated_time_to_visit'].fillna(df['estimated_time_to_visit'].median())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63aac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"RMSE: {rmse:.2f} hours\")\n",
    "print(f\"Mean actual visit time: {y_test.mean():.2f} hours\")\n",
    "print(f\"Model RÂ² score: {rf_model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance')\n",
    "plt.title('Feature Importance for Visit Time Prediction')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Visit Time (hours)')\n",
    "plt.ylabel('Predicted Visit Time (hours)')\n",
    "plt.title('Actual vs Predicted Visit Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a4be9",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_places(df, user_preferences=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommend places based on user preferences\n",
    "    \"\"\"\n",
    "    if user_preferences is None:\n",
    "        user_preferences = {\n",
    "            'preferred_time': 3.0,  # hours\n",
    "            'preferred_categories': ['historical', 'religious'],\n",
    "            'avoid_long_descriptions': True\n",
    "        }\n",
    "    \n",
    "    recommendations = df.copy()\n",
    "    \n",
    "    # Time preference score\n",
    "    time_diff = abs(recommendations['estimated_time_to_visit'] - user_preferences['preferred_time'])\n",
    "    recommendations['time_score'] = 1 / (1 + time_diff)\n",
    "    \n",
    "    # Category preference score\n",
    "    recommendations['category_score'] = recommendations['category'].apply(\n",
    "        lambda x: 1.0 if x in user_preferences['preferred_categories'] else 0.3\n",
    "    )\n",
    "    \n",
    "    # Description length preference (some users prefer concise descriptions)\n",
    "    if user_preferences.get('avoid_long_descriptions', False):\n",
    "        max_desc_length = recommendations['description_length'].quantile(0.7)\n",
    "        recommendations['desc_score'] = recommendations['description_length'].apply(\n",
    "            lambda x: 1.0 if x <= max_desc_length else 0.5\n",
    "        )\n",
    "    else:\n",
    "        recommendations['desc_score'] = 1.0\n",
    "    \n",
    "    # Popularity score (if available)\n",
    "    if 'popularity_score' in recommendations.columns:\n",
    "        pop_score = recommendations['popularity_score'] / recommendations['popularity_score'].max()\n",
    "    else:\n",
    "        pop_score = 0.5\n",
    "    \n",
    "    # Calculate overall recommendation score\n",
    "    recommendations['recommendation_score'] = (\n",
    "        recommendations['time_score'] * 0.3 +\n",
    "        recommendations['category_score'] * 0.4 +\n",
    "        recommendations['desc_score'] * 0.1 +\n",
    "        pop_score * 0.2\n",
    "    )\n",
    "    \n",
    "    # Sort by score and return top N\n",
    "    top_recommendations = recommendations.nlargest(top_n, 'recommendation_score')\n",
    "    \n",
    "    return top_recommendations[['name', 'category', 'region', 'estimated_time_to_visit', 'recommendation_score']]\n",
    "\n",
    "# Generate recommendations\n",
    "user_prefs = {\n",
    "    'preferred_time': 2.5,\n",
    "    'preferred_categories': ['historical', 'religious', 'natural'],\n",
    "    'avoid_long_descriptions': True\n",
    "}\n",
    "\n",
    "recommendations = recommend_places(df, user_prefs, top_n=10)\n",
    "print(\"Top 10 Recommended Places:\")\n",
    "print(recommendations.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53654d",
   "metadata": {},
   "source": [
    "## Advanced Analysis: Clustering Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c265ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Prepare data for clustering\n",
    "cluster_features = ['estimated_time_to_visit', 'name_length', 'description_length']\n",
    "if 'category_encoded' in df.columns:\n",
    "    cluster_features.append('category_encoded')\n",
    "if 'popularity_score' in df.columns:\n",
    "    cluster_features.append('popularity_score')\n",
    "\n",
    "X_cluster = df[cluster_features].fillna(0)\n",
    "X_cluster_scaled = StandardScaler().fit_transform(X_cluster)\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Visualize clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter)\n",
    "plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Place Clusters (PCA Visualization)')\n",
    "\n",
    "# Cluster characteristics\n",
    "plt.subplot(1, 2, 2)\n",
    "cluster_means = df.groupby('cluster')['estimated_time_to_visit'].mean()\n",
    "cluster_means.plot(kind='bar')\n",
    "plt.title('Average Visit Time by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Average Visit Time (hours)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"Cluster Analysis:\")\n",
    "for cluster_id in sorted(df['cluster'].unique()):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"  Size: {len(cluster_data)} places\")\n",
    "    print(f\"  Avg visit time: {cluster_data['estimated_time_to_visit'].mean():.2f} hours\")\n",
    "    print(f\"  Most common category: {cluster_data['category'].mode().iloc[0] if len(cluster_data['category'].mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"  Example places: {', '.join(cluster_data['name'].head(3).tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84d02f",
   "metadata": {},
   "source": [
    "## Export Results for Further Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enhanced dataset with ML features and clusters\n",
    "output_df = df.copy()\n",
    "output_df['predicted_visit_time'] = rf_model.predict(scaler.transform(X))\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv('travel_places_with_ml_insights.csv', index=False)\n",
    "print(\"Enhanced dataset saved as 'travel_places_with_ml_insights.csv'\")\n",
    "\n",
    "# Save recommendations\n",
    "recommendations.to_csv('place_recommendations.csv', index=False)\n",
    "print(\"Recommendations saved as 'place_recommendations.csv'\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete! ===\")\n",
    "print(\"You now have:\")\n",
    "print(\"1. A trained model for predicting visit times\")\n",
    "print(\"2. Place clusters for segmentation\")\n",
    "print(\"3. A recommendation system\")\n",
    "print(\"4. Enhanced dataset with ML insights\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
